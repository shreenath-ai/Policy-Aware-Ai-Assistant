## Policy-Aware AI Assistant

This project demonstrates a trustworthy AI system that answers
policy-related questions **only when supported by official documents**.

### Key Features
- Policy document ingestion (PDFs)
- Retrieval-Augmented Generation (RAG)
- Explicit refusal when evidence is missing
- Policy citations and confidence indicators

### How to Run
```bash
pip install -r requirements.txt
python ingest.py
streamlit run app.py

Evaluation is performed using a manually curated local test set (`tests.py`) covering valid, ambiguous, and out-of-scope queries.

# ğŸ“œ Policy-Aware AI Assistant

A responsible AI assistant designed to answer policy-related questions **only when supported by official documents**, prioritizing transparency, caution, and real-world applicability.

---

## ğŸš€ Project Overview

Modern AI systems often generate confident answers without verified sources, which is risky in regulated domains like healthcare, governance, and compliance.

This project addresses that gap by building a **Policy-Aware AI Assistant** that:
- Uses official policy documents as the single source of truth
- Retrieves evidence via semantic search (RAG)
- Answers **only when policy support exists**
- Safely refuses unsupported or ambiguous queries

---

## ğŸ§  Core Features

- ğŸ“š Retrieval-Augmented Generation (RAG)
- ğŸ” Evidence-based answering
- âŒ Safe refusal when no policy evidence exists
- ğŸ§¾ Source transparency
- ğŸ” Confidence indication
- ğŸ¨ Clean, professional UI
- âš–ï¸ Responsible AI guardrails

---

## ğŸ› ï¸ Tech Stack

- **Language:** Python 3.11+
- **UI:** Streamlit
- **Embeddings:** SentenceTransformers (all-MiniLM-L6-v2)
- **Vector Database:** ChromaDB
- **Document Parsing:** PyPDF + manual text ingestion
- **Architecture:** RAG (Retrieval-Augmented Generation)

---

## ğŸ“… Development Journey (Day-wise)

---

### ğŸŸ¢ Day 1 â€“ Ideation & Conceptualization

**Focus:**
- Identified hallucination risks in policy-sensitive AI use cases
- Defined the concept of a *Policy-Aware* assistant
- Scoped the solution around healthcare and governance policies (DHA, UAE laws)

**Outcome:**
- Clear problem statement
- Defined success criteria (answer only with evidence)

---

### ğŸŸ¢ Day 2 â€“ Environment Setup & Project Structure

**Focus:**
- Python virtual environment setup
- GitHub repository initialization
- Defined clean folder structure

**Project Structure:**
policy_aware_ai/
â”œâ”€â”€ app.py
â”œâ”€â”€ rag.py
â”œâ”€â”€ ingest.py
â”œâ”€â”€ data/
â”‚ â””â”€â”€ manual_policies/
â”‚ â””â”€â”€ dha_policy.txt
â”œâ”€â”€ vector_db/
â””â”€â”€ README.md


**Outcome:**
- Clean, modular project foundation

---

### ğŸŸ¢ Day 3 â€“ Building the RAG Pipeline

**Focus:**
- Implemented document ingestion
- Chunked policy text and generated embeddings
- Stored embeddings in ChromaDB
- Built semantic retrieval logic

**Outcome:**
- Functional RAG backend
- Evidence retrievable from policy documents

---

### ğŸŸ¢ Day 4 â€“ Optimization & Evaluation

**Focus:**
- Debugged retrieval edge cases
- Ensured refusal when no policy evidence exists
- Tested multiple query types
- Validated safety-first behavior

**Evaluation Criteria:**
- Evidence presence
- Refusal correctness
- Stability under ambiguous queries

**Outcome:**
- Reliable and conservative system behavior

---

### ğŸŸ¢ Day 5 â€“ UI Polish & User Experience

**Focus:**
- Designed a clean, enterprise-grade interface
- Clear separation between answers and refusals
- Added confidence indicators and source transparency
- Included disclaimers for responsible usage
- Applied subtle CSS polish for a premium look

**Outcome:**
- Demo-ready professional UI
- Improved clarity and user trust

---

### ğŸŸ¢ Day 6 â€“ Robustness, Security & Guardrails

**Focus:**
- Input validation to prevent misuse
- Exception handling to avoid crashes
- Logging for observability
- Reinforced evidence-gating logic
- Prepared security and hallucination mitigation explanations

**Outcome:**
- Stable, predictable, and judge-ready application

---

## ğŸ¤ Demo Philosophy

The system is intentionally conservative.

- If policy evidence exists â†’ answer transparently
- If policy evidence does not exist â†’ refuse safely

This prioritizes **trust over verbosity**.

---

## âš ï¸ Disclaimer

This assistant provides **informational guidance only**, based on uploaded policy documents.  
It does **not** constitute legal, regulatory, or professional advice.

---

## ğŸ Current Status

âœ… Core functionality complete  
âœ… UI polished  
âœ… Safety & guardrails implemented  
âœ… Ready for live demo and evaluation  

---

## ğŸ“Œ Future Enhancements

- OCR support for scanned PDFs
- Expanded policy coverage
- Role-based access controls
- Advanced confidence scoring

---

Built with a focus on **responsible AI**, **explainability**, and **real-world applicability**.
